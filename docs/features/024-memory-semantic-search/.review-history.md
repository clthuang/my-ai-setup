# Review History: 024-memory-semantic-search

## Stage 1: Spec-Reviewer Review - Iteration 1 - 2026-02-20T10:30:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Needs Revision

**Issues:**
- [blocker] [testability] AC1 "30-entry test fixture" undefined — no fixture file path or programmatic construction specified
- [blocker] [assumptions] Component 1 assumes .meta.json has slug field with no fallback
- [blocker] [completeness] Config validation for memory_relevance_weight unspecified
- [blocker] [testability] ACs not measurable enough (vague thresholds)
- [blocker] [assumptions] lastCompletedPhase availability unverified

**Changes Made:**
- Added Prerequisites section verifying .meta.json field availability
- Specified explicit normalization formula for prominence_score
- Added git error handling edge cases (detached HEAD, < 3 commits)
- Made all ACs measurable with concrete thresholds

---

## Stage 1: Spec-Reviewer Review - Iteration 2 - 2026-02-20T10:45:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Needs Revision

**Issues:**
- [blocker] AC1 test fixture still not programmatically defined
- [blocker] .meta.json fallback handling incomplete
- [blocker] Config validation contract not specified
- [warning] Diagnostic output active/inactive format ambiguous
- [warning] Git keyword extraction unbounded

**Changes Made:**
- Defined programmatic 30-entry fixture (10 parser, 20 other, equal prominence)
- Added try/except for .meta.json, skip on missing fields
- Specified config validation: non-numeric or out-of-range → fallback 0.6 with stderr warning
- Clarified diagnostic active vs inactive format
- Added max 20 keywords, dotfile exclusion

---

## Stage 1: Spec-Reviewer Review - Iteration 3 - 2026-02-20T11:15:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Approved (0 blockers, 6 warnings, 3 suggestions)

**Issues (warnings addressed):**
- [warning] [assumptions] FTS5 availability not guaranteed — fixed: updated Prerequisites wording
- [warning] [testability] AC2 contradicts Component 3 behavioral note — fixed: reworded to test fallback consistency not byte-identical parity
- [warning] [clarity] Active feature discovery duplication not acknowledged — fixed: added note about independent Python implementation
- [warning] [testability] AC1 fixture category-balance confound — fixed: all entries same category, parser entries lower prominence
- [warning] [assumptions] Git fallback chain ambiguous for <2 commits — fixed: explicit chain HEAD~3 → HEAD~1 → empty
- [warning] [clarity] Diagnostic truncation rule vague — fixed: append "..." only if exceeds 30 chars

---

## Stage 2: Phase Review - Iteration 0 - 2026-02-20T11:30:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 3 warnings, 2 suggestions)

**Issues (warnings addressed):**
- [warning] PRD language/domain detection mapping not explicit — fixed: added note that git file extensions serve as implicit language detection
- [warning] PRD deviation (persistent vs ephemeral index) not in Scope Boundaries — fixed: added to Out of Scope list
- [warning] Edge case for sanitized-to-empty query — fixed: treat as context_query=None, fall back to prominence
- [suggestion] Multiple active features handling — fixed: use most recently modified .meta.json
- [suggestion] AC4 benchmark verification method — accepted as manual verification during implementation review

---

## [REWORKED SPEC] Stage 1: Spec-Reviewer Review - Iteration 1 - 2026-02-20T12:00:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Needs Revision

**Issues:**
- [blocker] [assumptions] Gemini default output is 3072 dimensions, not 768. Spec must specify `output_dimensionality=768` parameter.
- [blocker] [completeness] MCP server infrastructure undefined — no server location, transport type, or registration mechanism specified.
- [blocker] [testability] AC5 keyword quality untestable — "specific to the entry content" is subjective with no objective criterion.
- [blocker] [assumptions] Local/global merge semantics ambiguous — spec says "single global database" but original system had local/global split.
- [warning] [completeness] Recency decay function undefined — "more recent might matter more" but no formula specified.
- [warning] [assumptions] Normalisation edge cases — what happens when max score for a signal is 0 or all entries have identical scores?
- [warning] [clarity] Ambiguous dual-write strategy in D9 — "both the SQLite database AND markdown files" needs to be definitive, not optional.
- [warning] [completeness] Missing metadata table for provider tracking — no mechanism to detect embedding provider changes.
- [warning] [clarity] Timeout budget allocation unclear — "within 3-second timeout" but no specific budget for the semantic pipeline.
- [warning] [completeness] Context query composition undefined — D2 references "context query" but no template or formula given.
- [warning] [assumptions] numpy dependency management — spec says pip but project uses uv/pyenv.
- [warning] [completeness] Reasoning field enforcement gap — D6 MCP tool should require reasoning field.

**Changes Made:**
- Fixed Gemini dimensionality: specified `output_dimensionality=768` parameter in D4
- Added MCP server details: Python stdio server at `plugins/iflow-dev/mcp/memory-server.py`, registered in `.mcp.json`
- Made AC5 testable: added generic stopword list, required 3+ content-specific keywords
- Clarified single global DB with `source_project` tracking origin (no local/global split)
- Added hyperbolic recency decay formula: `1.0 / (1.0 + days_since_updated / 30.0)` with 30-day half-life
- Added normalisation edge cases: max=0 → weight redistributed; identical scores → all normalised to 1.0
- Made D9 definitively dual-write (both SQLite AND markdown)
- Added `_metadata` table to D1 for provider/model/dimensions/schema_version tracking
- Specified 2-second budget for semantic pipeline within 3-second timeout
- Added full context query template with signal sources in D2
- Changed all pip references to uv/pyenv
- Made reasoning field required in D6 MCP tool interface

---

## [REWORKED SPEC] Stage 1: Spec-Reviewer Review - Iteration 2 - 2026-02-20T12:30:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Needs Revision

**Issues:**
- [blocker] [assumptions] Missing Gemini `taskType` parameter — RETRIEVAL_DOCUMENT for write, RETRIEVAL_QUERY for query
- [blocker] [assumptions] Missing L2 normalization for 768-dimension embeddings (Gemini requires it for sub-3072)
- [blocker] [assumptions] No API key configuration mechanism for embedding providers
- [warning] [testability] AC1 depends on third-party embedding quality, not reproducible
- [warning] [assumptions] Pure-Python cosine similarity over 10K x 768 would exceed 2-second budget
- [warning] [clarity] Content hash deduplication semantics (description-only vs multi-field) unclear
- [warning] [scope] D9 dual-write divergence — no reconciliation strategy
- [warning] [assumptions] Git diff fallback for shallow history (<3 commits) unspecified
- [warning] [traceability] Recency uses `updated_at` which re-embedding resets artificially
- [warning] [clarity] Category-balanced fill is undocumented behavior change from current system
- [warning] [testability] AC5 "derived from" is subjective, not mechanically verifiable
- [warning] [assumptions] MCP server registration location unclear (project root vs plugin-level .mcp.json)

**Changes Made:**
- Added Gemini taskType: RETRIEVAL_DOCUMENT (write) and RETRIEVAL_QUERY (query) to D4
- Added L2 normalization requirement for all embeddings in D4
- Added API key config via environment variables (GEMINI_API_KEY, VOYAGE_API_KEY, OPENAI_API_KEY) in D4
- Added AC1b unit test with pre-computed embeddings isolating ranking from embedding quality
- Changed pure-Python fallback: vector retrieval skipped entirely when numpy unavailable (keyword + prominence only)
- Specified content hash normalization formula matching current memory.py
- Clarified D9: SQLite is source of truth, markdown is append-only audit trail, D7 import rebuilds from markdown
- Added git diff fallback chain for shallow history (HEAD~3 → HEAD~1 → skip)
- Specified `updated_at` only updates on content changes/retro observations, NOT re-embedding
- Acknowledged category fill behavior change from priority-based to relevance-based in D3
- Tightened AC5: substring or morphological variant (mechanically verifiable)
- Clarified MCP registration in project root `.mcp.json` with JSON entry shape
- Added configuration defaults note
- Clarified AC9 precision (up to 10K entries, p95 over 10 runs)

---

## [REWORKED SPEC] Stage 1: Spec-Reviewer Review - Iteration 3 - 2026-02-20T13:00:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Approved (0 blockers, 6 warnings, 3 suggestions)

**Issues:**
- [warning] [assumptions] MTEB 68.32 score not independently verifiable from Gemini API docs
- [warning] [assumptions] Gemini free tier rate limits undocumented; bulk import/migration could hit 429
- [warning] [testability] AC9 network latency not a controlled variable, not reproducible across environments
- [warning] [clarity] D5 auto mode tier order implicit; keyword generation prompt unspecified
- [warning] [traceability] Content recency (updated_at) vs recall recency (last_recalled_at) could be confused
- [warning] [assumptions] Concurrent SQLite writes from MCP and retro — WAL mode not specified

**Changes Made:**
- Removed unverifiable MTEB score from D4
- Added HTTP 429 handling: pause re-embedding, resume at next retro
- Split AC9 into controllable local computation (<100ms mock) and best-effort end-to-end (<2s)
- Added auto mode tier order explanation and noted keyword prompt deferred to design
- Explicitly labeled recency (content) vs recall frequency in D3 prominence breakdown
- Added WAL journal mode and busy_timeout=5000 to Technical Constraints

---

## [REWORKED SPEC] Stage 1: Spec-Reviewer Review - Iteration 4 - 2026-02-20T13:30:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Needs Revision (4 blockers, 5 warnings — several false positives identified)

**Issues (valid, addressed):**
- [warning] [completeness] D5 keyword generation tier lacks timeout specs → Added 5-second timeout per tier, non-blocking note
- [warning] [clarity] Empty context query could waste API call → Explicitly skip API call when context is None
- [warning] [testability] AC9 contradicts Technical Constraints on hard vs best-effort timeout → Clarified 3-second is hard kill, 2-second is target

**Issues (false positives, not addressed):**
- [blocker] L2 normalization "already normalized" — spec already states normalizing pre-normalized vectors is a no-op
- [blocker] AC1 reproducibility — already addressed in iteration 3 with AC1b unit test
- [blocker] Scope mismatch with PRD phases — user explicitly rejected phased approach in brainstorm session
- [blocker] D5 keyword generation error handling — overspecified for spec level; deferred to design
- [warning] MCP registration in .mcp.json — manually maintained in this codebase, not auto-generated

**Changes Made:**
- Added 5-second timeout per keyword generation tier, non-blocking failures
- Explicit None handling for empty context query: skip API call, prominence-only ranking
- Clarified 3-second timeout as hard kill in Technical Constraints, 2-second as target budget

---

## [REWORKED SPEC] Stage 1: Spec-Reviewer Review - Iteration 5 - 2026-02-20T14:00:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Approved (0 blockers, 2 warnings, 1 suggestion)

**Issues:**
- [warning] [testability] AC9(a) mock embedding definition imprecise → Fixed: random float32 (10000,768), pre-normalized
- [warning] [clarity] D2 FTS5 behavior when context_query=None unclear → Fixed: skip both vector and FTS5
- [suggestion] [clarity] D4 L2 normalization detection — spec already says "no-op for pre-normalized", accepted as-is

**Changes Made:**
- Specified mock embedding definition for AC9(a)
- Clarified both vector AND FTS5 skipped when context_query=None

---

## [REWORKED SPEC] Stage 2: Phase Review - Iteration 0 - 2026-02-20T14:30:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 4 warnings, 3 suggestions)

**Issues:**
- [warning] Problem statement multi-sentence (reviewer: "clear and testable")
- [warning] Implementation detail depth constrains design (reviewer: "quality observation, not a blocker")
- [warning] AC format narrative not Given/When/Then (reviewer: "unambiguous")
- [warning] No Open Questions section

**Changes Made:**
- Added Open Questions section listing deferred items (keyword prompt, BLOB serialization)
- Other warnings are format preferences, spec content is unambiguous per reviewer's own assessment

---

## [REWORKED SPEC] Stage 2: Phase Review - Iteration 1 - 2026-02-20T15:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 0 warnings, 0 suggestions)

**Summary:** Spec is complete and ready for design. All requirements clearly defined with measurable acceptance criteria, scope boundaries explicit, technical constraints specified, open questions documented.

---

## Design Review - Iteration 1 - 2026-02-20T16:45:00Z

**Reviewer:** design-reviewer (skeptic)
**Decision:** Needs Revision

**Issues:**
- [blocker] [assumptions] Gemini SDK task_type uses strings not TaskType enum — code shows `TaskType.RETRIEVAL_DOCUMENT` but SDK uses string values
  Challenge: Code won't compile with nonexistent enum
- [blocker] [completeness] Retro-facilitator agent modification not specified — no file path, field names, or backward compatibility handling
  Challenge: Cannot implement dual-write without knowing agent output schema changes
- [blocker] [feasibility] First-run import will timeout — 50+ API calls for embedding generation at session start within 3-second budget
  Challenge: Import would exceed timeout, causing empty memory output
- [blocker] [assumptions] MCP server Python environment resolution unspecified — `.mcp.json` uses bare `python` but needs venv with numpy/mcp SDKs
  Challenge: MCP server would fail to start without correct Python path
- [blocker] [assumptions] Session-start injector Python environment resolution unspecified — needs venv Python for numpy but bash invokes bare `python3`
  Challenge: ImportError for numpy at session start
- [warning] [assumptions] Python config reader space stripping/type coercion not matching bash `tr -d ' '` behavior
- [warning] [completeness] collect_context() pseudocode missing from C4 component
- [warning] [assumptions] In-session Claude not available for MCP captures — tier selection doesn't account for invocation context
- [warning] [completeness] Output format new fields not specified (keywords, reasoning, references in output)
- [warning] [assumptions] Async MCP with sync sqlite3 — potential blocking concerns
- [warning] [assumptions] Step 4c global promotion interaction with SQLite DB unclear
- [warning] [assumptions] Corrupted embedding handling in np.vstack — no BLOB size validation

**Changes Made:**
- Fixed Gemini SDK: replaced TaskType enum with actual SDK string API (`types.EmbedContentConfig(task_type='RETRIEVAL_DOCUMENT')`)
- Specified retro-facilitator modification: exact file (`retro-facilitator.md`), added keywords/reasoning fields to output schema, backward compatibility defaults
- Added two-phase import strategy: Phase 1 inserts without embeddings (fast, no API), Phase 2 generates embeddings during retros in batches of 50
- MCP server uses venv Python directly: `plugins/iflow-dev/.venv/bin/python` in `.mcp.json` command
- Session-start resolves venv Python with bash fallback to bare `python3` if venv missing
- Added type coercion rules matching bash behavior
- Added full collect_context() pseudocode with feature discovery, spec parsing, git diff fallback chain
- Added context-aware tier selection (retro gets keywords from agent output, MCP/import starts at Haiku tier)
- Explicitly stated new fields stored-only, NOT rendered in output
- Noted sync sqlite3 acceptable for stdio single-connection server
- Detailed Step 4c interaction with single global DB, content hash dedup, markdown dual-write unchanged
- Added BLOB size validation in get_all_embeddings()

---

## Design Review - Iteration 2 - 2026-02-20T17:00:00Z

**Reviewer:** design-reviewer (skeptic)
**Decision:** Approved (0 blockers, 7 warnings, 3 suggestions)

**Issues:**
- [warning] [feasibility] Gemini SDK task_type parameter may change in future SDK versions
- [warning] [consistency] FTS5 indexes raw JSON array string for keywords — JSON punctuation causes tokenization noise
- [warning] [completeness] Venv bootstrapping undefined — no setup instructions, no diagnostic when venv missing
- [warning] [completeness] .mcp.json relative path resolution assumption undocumented
- [warning] [assumptions] No base class enforces L2 normalization — Protocol only, each adapter must remember
- [warning] [completeness] Config reader says "between --- delimiters" but bash grep has no delimiter concept
- [warning] [completeness] Prominence sub-component combination formula undefined (four inputs, no combination rule)

**Changes Made:**
- Added try/except for EmbedContentConfig task_type parameter with fallback
- Added create_provider() factory and NormalizingWrapper to centrally enforce L2 normalization
- Updated FTS5 triggers to strip JSON array syntax before indexing (REPLACE chain)
- Added FTS5 keyword storage note explaining JSON-to-space conversion
- Added TD11: Setup and Bootstrapping section with venv creation, diagnostic messages, MCP server behavior
- Documented .mcp.json path resolution assumption explicitly in TD7
- Fixed config reader: removed "between --- delimiters", now says "scan ALL lines" matching bash grep
- Added explicit prominence sub-component formula: 0.3*obs + 0.2*confidence + 0.3*recency + 0.2*recall
- Added keyword quality constraints to retro-facilitator agent modification matching TieredKeywordGenerator prompt

---

## Design Review - Iteration 3 - 2026-02-20T17:15:00Z

**Reviewer:** design-reviewer (skeptic)
**Decision:** Approved (0 blockers, 4 warnings, 3 suggestions)

**Issues:**
- [warning] [consistency] NormalizingWrapper.embed_batch() loops sequentially instead of delegating to inner's batch API
- [warning] [completeness] FTS5 REPLACE chain edge case with special chars in keywords — no validation specified
- [warning] [completeness] Zero entries diagnostic format not specified
- [warning] [assumptions] Import paths differ between injector.py (relative) and memory-server.py (sys.path) — not reconciled

**Changes Made:**
- Fixed embed_batch to delegate to inner.embed_batch() then normalize each result
- Added keyword validation: reject double quotes, square brackets, JSON-special chars in TieredKeywordGenerator
- Specified zero entries behavior: produce no output (matches current memory.py)
- Documented both import paths explicitly with smoke test requirement
- Added PRD fallback in collect_context() matching spec D2 Step 1

---

## Design Review - Iteration 4 - 2026-02-20T17:30:00Z

**Reviewer:** design-reviewer (skeptic)
**Decision:** Needs Revision (3 blockers, 4 warnings, 1 suggestion)

**Issues:**
- [blocker] [feasibility] Gemini SDK task_type try/except silently degrades instead of failing fast — produces wrong embeddings
- [blocker] [consistency] Deferred import embedding only triggers in retros — deadlock if user only uses MCP
- [blocker] [completeness] Keyword validation vs FTS5 trigger behavior asymmetry undocumented
- [warning] [assumptions] Config reader tr -d ' ' strips ALL spaces including internal — undocumented
- [warning] [feasibility] Zero vector from provider causes NaN in ranking
- [warning] [completeness] First-session prominence edge case undocumented
- [warning] [assumptions] collect_context sort by path string, not numeric ID

**Changes Made:**
- Moved SDK task_type validation to GeminiProvider.__init__() — fails fast with clear error message at init
- Clarified Phase 2 triggers on ANY write-path (retro + MCP), not just retros. Added pending_embeddings metadata tracking
- Documented FTS5 REPLACE applies only to keywords column, reasoning indexed as raw text
- Added defensive keyword validation regex: ^[a-z0-9][a-z0-9-]*$
- Documented config space stripping strips ALL spaces including internal
- Added zero-vector check (norm < 1e-9) → raises EmbeddingError
- Documented first-session prominence edge case
- Fixed collect_context sort to extract numeric ID via regex
- Added JSON parse error handling in collect_context for .meta.json files

---

## Design Review - Iteration 5 - 2026-02-20T17:45:00Z

**Reviewer:** design-reviewer (skeptic)
**Decision:** Needs Revision (3 blockers, 4 warnings) — ITERATION CAP REACHED (5/5)

**Unresolved Issues (carried forward as reviewerNotes):**
- [blocker] [completeness] TD6 retro skill Step 4 SQLite write interface unspecified — how does retrospecting SKILL.md Step 4 call the semantic_memory package for database writes?
- [blocker] [consistency] C3/TD6 keyword generation responsibility overlap — TieredKeywordGenerator vs retro-facilitator agent keyword production ambiguity
- [blocker] [completeness] Diagnostic line generation unspecified — which component produces it, how are candidate counts computed?
- [warning] [assumptions] FTS5 availability not guaranteed on all systems (optional compile-time extension)
- [warning] [consistency] TD9 re-embedding only mentions retro, should match TD7's "any write-path" language
- [warning] [completeness] Silent .meta.json parse failure with no stderr logging in collect_context
- [warning] [consistency] All-or-nothing keyword rejection vs per-keyword filtering

**Changes Made:**
None — iteration cap reached. Issues stored in .meta.json reviewerNotes for handoff reviewer.

---

## Stage 4: Handoff Review - Iteration 0 - 2026-02-20T17:50:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Needs Revision (3 blockers, 4 warnings)

**Issues:**
- [blocker] TD6 retro skill Step 4 SQLite write interface unspecified — no invocation mechanism for semantic_memory from SKILL.md Step 4
- [blocker] C3/TD6 keyword generation responsibility overlap — ambiguous whether retros use TieredKeywordGenerator or extract from agent output
- [blocker] Diagnostic line generation unspecified — no component assigned, RetrievalResult lacks metadata for candidate counts
- [warning] FTS5 availability not guaranteed — no detection mechanism
- [warning] TD9 re-embedding language says "per retro invocation", contradicts "any write-path" intent
- [warning] Silent .meta.json parse failure — no stderr logging for debugging
- [warning] All-or-nothing keyword rejection — wasteful, should filter per-keyword

**Changes Made:**
- Added writer.py CLI entry point (I9) for SKILL.md Step 4 invocation via Bash tool, with --entry-json and --entry-file variants
- Clarified keyword source: retros EXTRACT from agent output (no TieredKeywordGenerator), MCP/import use TieredKeywordGenerator at tier 2
- Added RetrievalResult dataclass with vector_candidate_count, fts5_candidate_count, context_query metadata
- Expanded injector.py (I6) diagnostic line composition with explicit field sources
- Added FTS5 availability detection in MemoryDatabase.__init__() with boolean flag and stderr warning
- Fixed TD9 language: "per retro invocation" → "per write-path invocation"
- Added stderr logging in collect_context() for .meta.json parse failures
- Changed keyword validation from all-or-nothing rejection to per-keyword filtering
- Updated TD1 package structure to include writer.py
- Added writer.py file location in I9

---

## Stage 4: Handoff Review - Iteration 1 - 2026-02-20T18:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 4 warnings, 2 suggestions)

**Issues:**
- [warning] NormalizingWrapper.embed_batch() silently passes zero vectors instead of raising EmbeddingError like embed()
- [warning] fts5_available flag not exposed in I1 interface specification
- [warning] content_hash() formula not centralized — multiple components could reimplement inconsistently
- [warning] RankingEngine.rank() receives candidates dict but not signal availability — can't distinguish "no matches" from "signal unavailable" for weight redistribution

**Changes Made:**
- Fixed embed_batch() to raise EmbeddingError on norm < 1e-9, matching embed() behavior
- Added fts5_available property to I1 MemoryDatabase interface
- Centralized content_hash() in __init__.py, documented as shared utility in TD1
- Changed RankingEngine.rank() to accept RetrievalResult instead of raw candidates dict, documented weight redistribution logic

---

## Stage 4: Handoff Review - Iteration 2 - 2026-02-20T18:10:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 2 warnings, 1 suggestion)

**Issues:**
- [warning] MarkdownImporter._parse_markdown_entries() lacks markdown format details
- [warning] RecallTracker (C8) has no corresponding interface section

**Changes Made:**
- Added markdown format documentation to I8 _parse_markdown_entries docstring (heading patterns, metadata lines, category derivation)
- Clarified C8 RecallTracker is a thin utility inlined into injector.py, not a separate module — calls db.update_recall()

---

## Stage 4: Handoff Review - Iteration 3 - 2026-02-20T18:20:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 1 warning, 1 suggestion)

**Issues:**
- [warning] Design contains extensive implementation-level code that risks over-constraining plan phase (reviewer: "No action needed for plan readiness")

**Changes Made:**
- Added note at top of Interfaces section: code snippets are illustrative contracts, not prescriptive implementations

---

## Stage 4: Handoff Review - Iteration 4 - 2026-02-20T18:30:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 0 warnings, 0 suggestions)

**Summary:** Design is comprehensive and ready for implementation planning. All components, interfaces, decisions, risks, and spec traceability verified.

---

## Stage 1: Plan Review - Iteration 1 - 2026-02-20T18:40:00Z

**Reviewer:** plan-reviewer (skeptic)
**Decision:** Needs Revision (4 blockers, 7 warnings, 3 suggestions)

**Issues:**
- [blocker] No test items as separate plan steps — TDD violation. All 16 items are implementation.
- [blocker] pyproject.toml (5.4) in Phase 5 but needed by Phase 2 for numpy/SDK imports.
- [blocker] Package import path unresolved — `from semantic_memory import ...` fails without PYTHONPATH.
- [blocker] MCP FastMCP import path unverified — `mcp` vs `fastmcp` PyPI packages differ.
- [warning] RankingEngine (2.3) imports RetrievalResult from retrieval.py (3.1) — circular dep.
- [warning] No rollback strategy for session-start.sh modification (5.1).
- [warning] OllamaProvider "stub" is ambiguous — placeholder vs real implementation.
- [warning] retro-facilitator backward compat untested functionally (5.2).
- [warning] Database item 1.3 is monolithic — 14 methods with no intermediate checkpoint.
- [warning] google-genai SDK API surface unverified against EmbedContentConfig assumptions.
- [warning] MCP server testing strategy unclear — how to unit test async MCP tool handlers.
- [suggestion] No commit strategy for incremental review.
- [suggestion] Voyage/OpenAI provider scope unclear.
- [suggestion] AC2 cross-project retrieval not explicitly tested.

**Changes Made:**
- Moved pyproject.toml to Phase 0 (before all code)
- Added types.py to Phase 1 for shared dataclasses (breaks circular dep)
- Added explicit test items per phase
- Clarified import path strategy (PYTHONPATH / sys.path)
- Verified MCP import path (`from mcp.server.fastmcp import FastMCP` from `mcp[cli]` package)
- Clarified OllamaProvider as NotImplementedError stub
- Split database into 1.3a (basic CRUD) and 1.3b (FTS5 + embedding methods)
- Added SDK verification step to embedding provider
- Added rollback note to session-start.sh
- Added functional backward-compat test to retro integration
- Added commit strategy note
- Added AC2 cross-project test to integration testing
- Clarified provider scope (Gemini full, Ollama stub, Voyage/OpenAI not implemented)

---

## Stage 1: Plan Review - Iteration 2 - 2026-02-20T18:50:00Z

**Reviewer:** plan-reviewer (skeptic)
**Decision:** Approved with 6 warnings, 3 suggestions (zero blockers)

**Issues:**
- [warning] Retro-facilitator field mapping to writer.py undocumented (5.2)
- [warning] Gemini SDK task_type parameter naming uncertainty (0.1/2.1) — mitigated by Phase 0.1 verification
- [warning] Importer keyword generation at session start could blow 3s timeout (3.2/4.1)
- [warning] Same timeout concern from injector perspective (4.1)
- [warning] TDD ordering: tests after implementation per phase — reviewer says acceptable
- [warning] Heuristic heading format discrepancy — plan correctly follows memory.py

**Changes Made:**
- Added explicit field mapping note to 5.2 (text→description, provenance→references, etc.)
- Added keyword_gen=None note to importer (3.2) and injector (4.1) for first-run import
- Added note about heuristic heading format to importer (3.2)
- Added embed_batch() implementation note to GeminiProvider (2.1)
- Added SDK version fallback note to 2.1
- Added test-alongside-implementation clarification to 1.4

---

## Stage 1: Plan Review - Iteration 3 - 2026-02-20T19:00:00Z

**Reviewer:** plan-reviewer (skeptic)
**Decision:** Approved with 4 warnings, 2 suggestions (zero blockers)

**Issues:**
- [warning] I8 type annotation shows non-optional keyword_gen but plan passes None (3.2/4.1)
- [warning] validate.sh doesn't run Python checks; pytest covers compilation (6.2)
- [warning] importer code-level vs runtime dependency on embedding/keywords (3.2)
- [warning] retro-facilitator prompt modification is soft instruction (5.2) — acceptable risk

All warnings: reviewer explicitly says "No plan change needed" for each.

**Changes Made:**
- Added type annotation note to 3.2 (keyword_gen: KeywordGenerator | None)
- Clarified 6.2 that validate.sh checks for regressions, Python compilation verified by pytest
- (Warnings 3 and 4 require no plan change per reviewer)

---

## Stage 1: Plan Review - Iteration 4 - 2026-02-20T19:10:00Z

**Reviewer:** plan-reviewer (skeptic)
**Decision:** Approved with 1 warning, 1 suggestion (zero blockers)

**Issues:**
- [warning] injector.py and writer.py need sys.path.insert like memory-server.py — plan's import strategy only mentions MCP server and tests
- [suggestion] Design I8 heuristic heading example is wrong, plan already flags this correctly

**Changes Made:**
- Updated import path strategy paragraph to explicitly list all 3 entry points (injector, writer, MCP server) needing sys.path.insert
- Added note: design mentions "relative imports" for injector.py — use absolute imports with sys.path instead

---

## Stage 1: Plan Review - Iteration 5 (FINAL) - 2026-02-20T19:20:00Z

**Reviewer:** plan-reviewer (skeptic)
**Decision:** Approved with 2 warnings, 2 suggestions (zero blockers) — ITERATION CAP REACHED (5/5)

**Issues:**
- [warning] keyword_gen type annotation: I8 shows non-optional but plan passes None — plan already documents `KeywordGenerator | None` clearly at 3.2
- [warning] integration test mock embeddings need controlled prominence for deterministic results — plan already specifies "similar observation counts" at 6.1
- [suggestion] OllamaProvider HTTP client library choice not specified — not a plan-level concern
- [suggestion] release.sh `uv sync` step placement — deferred to implementation

All warnings: reviewer explicitly says "No plan change needed" for each.

**Changes Made:**
None — reviewer approved all items as already addressed. Iteration cap reached.

**Unresolved Concerns (carried to .meta.json):**
- keyword_gen type annotation mismatch between design I8 and plan 3.2 (plan is correct, design shows non-optional)
- Integration test mock embeddings should use controlled prominence values for deterministic ranking

---

## Stage 2: Chain Review - Iteration 0 - 2026-02-20T19:30:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Needs Revision (0 blockers, 3 warnings, 2 suggestions)

**Issues:**
- [warning] 5.1 verification doesn't confirm semantic path was taken (only tests fallback)
- [warning] Import path deviation from design TD7 not noted at point of implementation (4.1)
- [warning] AC3 (recall tracking) and AC4 (MCP capture) not covered in Phase 6.1 integration tests
- [suggestion] TDD compliance note inconsistent between test item ordering and prose
- [suggestion] Definition of Done items lack AC references

**Changes Made:**
- Added `semantic: active` / `semantic: disabled` diagnostic line check to 5.1 verification
- Added import path deviation note to 4.1 deliverable (references preamble)
- Added AC3 (recall tracking over 3 cycles) and AC4 (MCP business logic → retrievable) to 6.1 integration tests
- Added controlled prominence (obs_count=1, confidence=medium for all) to 6.1 test fixture

---

## Stage 2: Chain Review - Iteration 1 - 2026-02-20T19:40:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 0 warnings, 2 suggestions)

**Summary:** Plan is comprehensive and ready for task breakdown. All design components, interfaces, and technical decisions covered. Dependencies explicit, parallelism identified, sequencing logical. Two minor suggestions applied (DoD AC list updated to include AC3/AC4).

---

## Task Review Iteration 1 - 2026-02-20T20:00:00Z

**Decision:** Needs Revision

**Issues:**
- [blocker] Task 2.4: Dependency listed as 'T1.1 (types.py only)' but uses config values → add T1.2 dependency
- [blocker] Task 2.2: Execution Strategy parallel group labeling inconsistent → standardize group numbering
- [blocker] Task 1.5: T1.5 claims to block T2.1/T2.3/T2.4 but those tasks don't list T1.5 as dependency → add T1.5 to Phase 2 depends-on
- [blocker] Task 2.5: Same cross-reference inconsistency (blocks T3.1 but T3.1 doesn't list T2.5) → add T2.5 to Phase 3 depends-on
- [warning] Test task convention inconsistent (phase tests as hard gates vs optional) → establish convention: phase tests ARE hard gates
- [warning] T3.2 depends on T2.1/T2.3 but never uses them at runtime (keyword_gen=None) → clarify type-level vs runtime deps
- [warning] T5.2 could be misread as adding write instructions to read-only agent → clarify agent outputs text only, SKILL.md does the write
- [warning] T5.1 doesn't clarify interaction between memory_injection_enabled and memory_semantic_enabled → add toggle precedence
- [warning] T1.3 doesn't enumerate the 15 columns → enumerate all 16 columns
- [warning] T6.1 AC9a timing boundary unclear → clarify: matmul + ranking only, excluding DB I/O and embedding generation
- [warning] T4.1 first-run import should also pass provider=None → add provider=None explicitly

**Changes Made:**
- Established phase gate convention: test tasks (T1.5, T2.5, T3.3, T4.4) are hard gates for next phase
- Rewrote dependency graph with [PHASE GATE] markers and consistent bidirectional references
- Standardized Execution Strategy group numbering with explicit phase gate sections
- Fixed all Depends-on/Blocks cross-references for bidirectional consistency
- Added T1.2 to T2.4 dependencies (now T1.5 phase gate covers both T1.1 and T1.2)
- Enumerated all 16 database columns in T1.3
- Clarified T3.2 type-level vs runtime dependency in Depends-on annotation
- Added toggle precedence to T5.1: memory_injection_enabled gates both paths
- Clarified T5.2: retro-facilitator is read-only analysis agent, SKILL.md handles DB write
- Specified AC9a timing boundary in T6.1: matmul + ranking only
- Added provider=None to T4.1 first-run import and T4.4 test
- Added plan-to-task mapping table
- Updated critical path to 15 tasks reflecting phase gates

---

## Task Review Iteration 2 - 2026-02-20T20:15:00Z

**Decision:** Needs Revision (approved=true but 3 warnings under strict threshold)

**Issues:**
- [warning] T1.3: Primary key column named `entry_id` diverges from design schema `id TEXT PRIMARY KEY` → align to `id`
- [warning] T1.3: Source column values listed as "import"|"mcp"|"retro" but design/spec uses CHECK(source IN ('retro', 'session-capture', 'manual', 'import')) → align to spec/design values
- [warning] T6.1: Integration tests omit AC6 (toggle fallback), AC7 (degradation chain) → add both as integration test scenarios
- [suggestion] T1.3: INSERT OR REPLACE vs ON CONFLICT for upsert — kept INSERT OR REPLACE for simplicity
- [suggestion] T2.4: obs normalization formula clarity — already specified in detail
- [suggestion] T4.3: MCP server project root for config — config passed via lifespan context
- [suggestion] Plan 2.1 split well-documented — no change needed

**Changes Made:**
- Fixed T1.3: `entry_id TEXT PRIMARY KEY` → `id TEXT PRIMARY KEY` to match design schema
- Fixed T1.3: source values from `"import"|"mcp"|"retro"` → `CHECK(source IN ('retro', 'session-capture', 'manual', 'import'))` matching spec/design
- Added `source='session-capture'` to T4.3 MCP server _process_store_memory step per spec D6
- Added AC6 (toggle fallback) and AC7 (degradation chain) integration test scenarios to T6.1
- Updated T6.1 from 5 to 7 AC test scenarios

---

## Task Review Iteration 3 - 2026-02-20T20:30:00Z

**Decision:** Needs Revision (approved=true but 6 warnings under strict threshold)

**Issues:**
- [warning] T1.3: INSERT OR REPLACE deletes old row, cannot increment observation_count → change to INSERT...ON CONFLICT(id) DO UPDATE
- [warning] T3.2: Heading format ambiguous about prefix stripping — only "Anti-Pattern: " and "Pattern: " (no "Heuristic: ") → make explicit
- [warning] T2.4: obs normalization scope unclear — should be across ALL entries passed to rank(), not just candidates → clarify
- [warning] T4.1: import_all() missing project_root argument specification → add explicit call signature
- [warning] T6.1: AC6 toggle test conflates bash-level and Python-level boundaries → clarify bash integration test approach
- [warning] T5.1: Diagnostic verification too vague → specify substring checks on stdout
- [suggestion] T1.2: Config reader should only match keys in defaults dict
- [suggestion] T2.3: Add stopword list cross-reference assertion in test
- [suggestion] T2.1: Clarify embed_batch() approach for Gemini SDK
- [suggestion] T5.2: Check SKILL.md stays under 500 lines after modifications
- [suggestion] T4.2: Reorder provider migration check before upsert
- [suggestion] Overall: Note release script sync after feature merge

**Changes Made:**
- Fixed T1.3: Changed INSERT OR REPLACE to INSERT...ON CONFLICT(id) DO UPDATE SET observation_count = observation_count + 1
- Fixed T3.2: Explicit prefix stripping — only "Anti-Pattern: " and "Pattern: ", NO "Heuristic: " prefix
- Fixed T2.4: Clarified norm_obs computed across ALL entries passed to rank(), max=0 → 0
- Fixed T4.1: Added explicit import_all() call with project_root=args.project_root, global_store=args.global_store
- Fixed T6.1 AC6: Changed to bash integration test verifying session-start.sh invokes correct script
- Fixed T5.1: Made diagnostic test explicit with substring checks on captured stdout

---

## Task Review Iteration 4 - 2026-02-20T20:45:00Z

**Decision:** Needs Revision (approved=true but 2 warnings under strict threshold)

**Issues:**
- [warning] T1.3: Keyword merge strategy unspecified ("merge keywords if provided" ambiguous) → specify replace-if-non-null semantics
- [warning] T2.4: Confidence mapping should note it's a fixed mapping, not data-dependent normalization → add clarification
- [suggestion] T4.1: Output format two-level structure (category sections + entries) could be more explicit
- [suggestion] T6.1: AC6 bash test approach needs one concrete implementation
- [suggestion] T5.1: Toggle precedence test (memory_injection_enabled=false skips both) not in test criteria
- [suggestion] T3.2: Filename allowlist for knowledge bank scanning
- [suggestion] Overall: Dependency graph, phase gates, parallel groups all verified correct

**Changes Made:**
- Fixed T1.3: Specified keyword merge as replace-if-non-null (not union). Same for description, reasoning, references.
- Fixed T2.4: Added "(fixed, not data-dependent)" clarification to confidence mapping

---

## Task Review Iteration 5 - 2026-02-20T21:00:00Z

**Decision:** Approved

**Issues:**
- [suggestion] T2.4: Use exact fractions 2/3 and 1/3 to avoid float comparison issues in tests
- [suggestion] T4.1: Clarify entry heading uses singular prefix matching memory.py output format
- [suggestion] T3.1: Specify "active" means .meta.json status field equals "active"
- [suggestion] T1.3: Enumerate complete ON CONFLICT SET clause explicitly
- [suggestion] Overall: Document is in good shape, all blockers resolved

**Changes Made:**
None required — all issues are suggestions only.

---

## Stage 2: Chain Review - Iteration 0 - 2026-02-20T21:15:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Needs Revision (approved=true but 3 warnings under strict threshold)

**Issues:**
- [warning] T2.4: Confidence mapping spec-to-design drift (1.0/0.67/0.33 vs spec's normalization interpretation) → add code comment documenting provenance
- [warning] T6.1: AC1 (full embedding quality) intentionally omitted but not documented → add note in test file
- [warning] T5.2: SKILL.md line budget not checked after modification → add done-when check
- [suggestion] T0.1: Working directory context for uv sync commands
- [suggestion] Critical path may shift if T2.4 exceeds T2.1+T2.2 combined
- [suggestion] AC references in T6.1 already adequate with parenthetical descriptions

**Changes Made:**
- Fixed T2.4: Changed to exact fractions (2/3, 1/3), added code comment provenance note
- Fixed T6.1: Added step 10 noting AC1 intentional omission with comment instruction
- Fixed T5.2: Added SKILL.md <500 lines budget check to done-when criteria

---

## Stage 2: Chain Review - Iteration 1 - 2026-02-20T21:30:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Needs Revision (approved=true, 4 warnings, but ALL 4 have "No action needed" suggestions — observational notes rather than actionable issues)

**Issues (all informational):**
- [warning] T1.3: 16-column count is correct upon full enumeration → "No action needed"
- [warning] T2.4: Confidence mapping provenance already well-handled → "No change needed"
- [warning] T5.1: Done-when requires injector pipeline which is gated by T4.4 → "No change needed"
- [warning] T6.1: AC1 omission well-documented → "No action needed"
- [suggestion] T2.2 sequential split well-motivated → no change
- [suggestion] T4.3 test coverage via T4.4 → no change
- [suggestion] Critical path accurate → no change

**Changes Made:**
None — all warnings explicitly had "No action needed" / "No change needed" suggestions from the reviewer itself.

---

## Stage 2: Chain Review - Iteration 2 - 2026-02-20T21:45:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (approved=true, 0 blockers, 0 warnings, 5 suggestions only)

**Issues (all suggestions — confirmatory observations):**
- [suggestion] T1.3: 16-column count verified correct against spec D1 schema
- [suggestion] T2.4: Confidence mapping provenance tracing explicit with design C5/spec D3 references
- [suggestion] T6.1: AC1 omission documented and justified with comment instruction
- [suggestion] T5.2: SKILL.md budget check built into done-when with fallback mitigation
- [suggestion] T4.1: Import-without-API-calls constraint correctly reflected for 3s timeout

**Changes Made:**
None required — all issues are suggestions only. PASS under strict threshold.

---

## Implementation Review - Iteration 1 - 2026-02-20T23:10:00Z

**Implementation Review:** Issues found
  - Level 1 (Tasks): fail (2 warnings)
  - Level 2 (Spec): fail (2 blockers)
  - Level 3 (Design): fail (1 blocker, 2 warnings)
  - Level 4 (PRD): fail (1 issue)
**Quality Review:** Issues found (approved=true, 2 warnings)
**Security Review:** Issues found (approved=true, 2 warnings)

**Issues:**
- [blocker] [design] implementation-reviewer: _find_active_feature() does not filter by status=="active" — completed/archived features could be selected (at: retrieval.py:183-205)
  Suggestion: Add status check after loading .meta.json
- [blocker] [spec] implementation-reviewer: embedding.py top-level import of google-genai prevents graceful degradation when SDK not installed (at: embedding.py:12-13)
  Suggestion: Use try/except ImportError at module level
- [warning] [tasks] implementation-reviewer: OllamaProvider stub missing from embedding.py per T2.1 (at: embedding.py)
  Suggestion: Add stub class that raises NotImplementedError
- [warning] [tasks] implementation-reviewer: pyproject.toml requires-python >=3.10 vs spec >=3.9 (at: pyproject.toml:4)
  Suggestion: Accepted — 3.10 is practical minimum due to union syntax
- [warning] [design] implementation-reviewer: MCP server filename memory_server.py vs design's memory-server.py (at: mcp/memory_server.py)
  Suggestion: Accepted — underscore is Python convention
- [warning] [spec] implementation-reviewer: context_query=None returns empty instead of all entries for prominence-only ranking (at: retrieval.py:122-123)
  Suggestion: Pass all entries with zero scores when context is None
- [warning] [security] security-reviewer: FTS5 MATCH crashes on special characters in query (at: database.py:266-275)
  Suggestion: Wrap in try/except sqlite3.OperationalError
- [warning] [security] security-reviewer: CVE-2025-7709 SQLite FTS5 integer overflow (at: pyproject.toml)
  Suggestion: Document minimum SQLite version — accepted as informational
- [warning] [quality] code-quality-reviewer: Mutable default argument references: list[str] = [] (at: memory_server.py:195)
  Suggestion: Change to None default
- [warning] [quality] code-quality-reviewer: writer.py accesses db._conn directly bypassing public API (at: writer.py:99-103)
  Suggestion: Add public update_keywords() to MemoryDatabase

**Changes Made:**
- Fixed _find_active_feature: added `if meta.get("status") != "active": continue` filter
- Fixed embedding.py: wrapped google-genai import in try/except ImportError with module-level fallback to None
- Added OllamaProvider stub class that raises NotImplementedError on construction
- Added 'ollama' to _PROVIDER_ENV_KEYS map with None (no API key needed)
- Updated create_provider to handle 'ollama' provider name
- Fixed context_query=None: now returns all entries with zero CandidateScores for prominence-only ranking
- Fixed FTS5 MATCH: wrapped in try/except sqlite3.OperationalError returning empty list
- Fixed mutable default: changed `references: list[str] = []` to `references: list[str] | None = None`
- Added `update_keywords()` public method to MemoryDatabase
- Fixed writer.py to use db.update_keywords() instead of db._conn.execute()
- Fixed file handle leak in retrieval.py: replaced bare open() with context manager
- Updated MockDatabase/MockDB in tests for new get_all_entries() dependency
- Updated tests for new None context_query behavior (all entries returned)

---
