---
name: retrospecting
description: Runs data-driven AORTA retrospective using retro-facilitator agent with full intermediate context. Use when the user says 'run retro', 'capture learnings', 'reflect on feature', or 'update knowledge bank'.
---

# Retrospective

## Static Reference
Data-driven AORTA retrospective using retro-facilitator agent.

## Process

### Step 0: Recovery Check for Interrupted Retros

Before assembling context, check if a previous retro run was interrupted after writing `retro.md` but before completing knowledge bank updates.

1. Check if `{iflow_artifacts_root}/features/{id}-{slug}/retro.md` exists
2. If it does NOT exist → skip to Step 1 (fresh run)
3. If it exists, check for completed KB updates:
   - Grep each KB markdown file (`patterns.md`, `anti-patterns.md`, `heuristics.md`) for `Last observed: Feature #{id}`
   - Call `search_memory` MCP with `query: "Feature {id}"`, `limit: 20` — check for DB entries referencing this feature
4. If retro.md exists AND both KB markdown entries AND DB entries are present → retro already completed, skip to Step 5 (commit)
5. If retro.md exists but KB markdown OR DB entries are missing → recovery needed:
   - Parse the "Act (Knowledge Bank Updates)" section from retro.md
   - Extract patterns, anti-patterns, and heuristics entries with their metadata

**YOLO mode:** Auto-select "Resume" without prompting.

**Normal mode:**
```
AskUserQuestion:
  questions: [{
    "question": "retro.md exists but knowledge bank updates are incomplete. How should we proceed?",
    "header": "Retro Recovery",
    "options": [
      {"label": "Resume", "description": "Persist missing KB/DB entries from existing retro.md"},
      {"label": "Re-run", "description": "Discard existing retro.md and run full retrospective"},
      {"label": "Skip", "description": "Leave retro as-is, proceed to commit"}
    ],
    "multiSelect": false
  }]
```

- **Resume**: Jump to Step 3a using parsed entries, then continue through Steps 3b, 4, 4c, 5
- **Re-run**: Continue to Step 1 (overwrite retro.md)
- **Skip**: Jump to Step 5

### Step 1: Assemble Context Bundle

Read and collect all intermediate data:

**a. Phase Metrics** — Read `.meta.json` and extract:
- Phase timings: all `phases.*.started` / `phases.*.completed` timestamps
- Iteration counts: `phases.*.iterations`
- Reviewer notes: `phases.*.reviewerNotes`
- Mode: Standard or Full

**b. Review History** — Read `.review-history.md`:
- If file exists: capture full content
- If file doesn't exist: note "No review history available"

**c. Implementation Log** — Read `implementation-log.md`:
- If file exists: capture full content
- If file doesn't exist: note "No implementation log available"

**d. Git Summary** — Run via Bash:
```bash
git log --oneline {iflow_base_branch}..HEAD | wc -l
```
```bash
git diff --stat {iflow_base_branch}..HEAD
```

**e. Artifact Stats** — Read and count lines for each artifact:
- `spec.md`, `design.md`, `plan.md`, `tasks.md`
- Note which artifacts exist vs missing

**f. AORTA Framework** — Read `references/aorta-framework.md` from this skill's directory.

### Step 2: Dispatch retro-facilitator

```
Task tool call:
  description: "Run AORTA retrospective"
  subagent_type: iflow:retro-facilitator
  model: opus
  prompt: |
    Run AORTA retrospective for feature {id}-{slug}.

    ## Context Bundle

    ### Phase Metrics
    {assembled .meta.json extract — phase timings, iterations, reviewer notes, mode}

    ### Review History
    {.review-history.md content, or "No review history available"}

    ### Implementation Log
    {implementation-log.md content, or "No implementation log available"}

    ### Git Summary
    Commits: {commit count}
    Files changed:
    {git diff --stat output}

    ### Artifact Stats
    - spec.md: {line count or "missing"}
    - design.md: {line count or "missing"}
    - plan.md: {line count or "missing"}
    - tasks.md: {line count or "missing"}

    ### AORTA Framework
    {content of references/aorta-framework.md}

    Return structured JSON with observe, review, tune, act sections
    plus retro_md content.
```

**Fallback:** If retro-facilitator agent fails, fall back to investigation-agent:

```
Task tool call:
  description: "Gather feature learnings"
  subagent_type: iflow:investigation-agent
  model: sonnet
  prompt: |
    Gather retrospective data for feature {id}-{slug}.

    Read:
    - Feature folder contents ({iflow_artifacts_root}/features/{id}-{slug}/)
    - Git log for this branch
    - .review-history.md if exists

    Identify:
    - What went well
    - What could improve
    - Patterns worth documenting
    - Anti-patterns to avoid

    Return structured findings as JSON:
    {
      "what_went_well": [...],
      "what_could_improve": [...],
      "patterns": [...],
      "anti_patterns": [...],
      "heuristics": []
    }
```

If using fallback, generate retro.md in the legacy format (What Went Well / What Could Improve / Learnings Captured).

**Fallback learning persistence:** After writing retro.md, also execute Steps 3a, 4, and 4c
using the investigation-agent's JSON output. Map fields:
- `patterns` array → Step 4 patterns entries
- `anti_patterns` array → Step 4 anti-patterns entries
- `heuristics` array → Step 4 heuristics entries

For each entry, set defaults for fields the investigation-agent doesn't produce:
- `text`: the string from the array
- `name`: derive from text (first ~60 chars)
- `confidence`: "low"
- `keywords`: []
- `reasoning`: ""
- `provenance`: "Feature #{id} (investigation-agent fallback)"

Skip Step 4b (validation of pre-existing entries) during fallback.

### Step 3: Write retro.md

Write `{iflow_artifacts_root}/features/{id}-{slug}/retro.md` using the `retro_md` field from the retro-facilitator agent response.

The retro_md follows the AORTA format:

```markdown
# Retrospective: {Feature Name}

## AORTA Analysis

### Observe (Quantitative Metrics)
| Phase | Duration | Iterations | Notes |
|-------|----------|------------|-------|
| ... | ... | ... | ... |

{Quantitative summary}

### Review (Qualitative Observations)
1. **{Observation}** — {evidence}
2. ...

### Tune (Process Recommendations)
1. **{Recommendation}** (Confidence: {level})
   - Signal: {what was observed}
2. ...

### Act (Knowledge Bank Updates)
**Patterns added:**
- {pattern text} (from: {provenance})

**Anti-patterns added:**
- {anti-pattern text} (from: {provenance})

**Heuristics added:**
- {heuristic text} (from: {provenance})

## Raw Data
- Feature: {id}-{slug}
- Mode: {mode}
- Branch lifetime: {days or N/A}
- Total review iterations: {count}
```

### Step 3a: Persist Learnings to DB via store_memory MCP

For each entry in `act.patterns`, `act.anti_patterns`, `act.heuristics` from the retro-facilitator response:

Call `store_memory` MCP tool with:
- `name` — entry name
- `description` — the learning text
- `reasoning` — reasoning from agent (or empty string)
- `category` — one of `patterns`, `anti-patterns`, `heuristics`
- `references` — `["{provenance}"]`
- `confidence` — confidence from agent (or `"medium"`)

Track each entry's name in a local list for verification in Step 3b.

**Fallback** if `store_memory` MCP is unavailable:
```bash
PLUGIN_ROOT=$(ls -d ~/.claude/plugins/cache/*/iflow*/*/hooks 2>/dev/null | head -1 | xargs dirname)
if [[ -n "$PLUGIN_ROOT" ]] && [[ -x "$PLUGIN_ROOT/.venv/bin/python" ]]; then
  PYTHONPATH="$PLUGIN_ROOT/hooks/lib" "$PLUGIN_ROOT/.venv/bin/python" -m semantic_memory.writer \
    --action upsert --global-store ~/.claude/iflow/memory \
    --entry-json '{"name":"...","description":"...","reasoning":"...","category":"...","source":"retro","confidence":"...","references":"[...]"}'
else
  # dev workspace fallback
  PYTHONPATH=plugins/iflow/hooks/lib python3 -m semantic_memory.writer \
    --action upsert --global-store ~/.claude/iflow/memory \
    --entry-json '{"name":"...","description":"...","reasoning":"...","category":"...","source":"retro","confidence":"...","references":"[...]"}'
fi
```

On failure: log to stderr, continue (do not block retro completion).

### Step 3b: Verify DB Entries

After all `store_memory` calls in Step 3a:

1. Call `search_memory` MCP with `query: "Feature {id} retrospective learnings"`, `limit: 20`
2. For each entry stored in Step 3a, check its name appears in search results
3. Missing entries: retry `store_memory` once per missing entry
4. Output: `"DB persistence: {n}/{total} entries verified"`

### Step 4: Update Knowledge Bank

From the `act` section of the agent response, append entries to knowledge bank files:

0. Ensure directory exists: `mkdir -p {iflow_artifacts_root}/knowledge-bank/`

1. For each pattern in `act.patterns`:
   - Append to `{iflow_artifacts_root}/knowledge-bank/patterns.md`
2. For each anti-pattern in `act.anti_patterns`:
   - Append to `{iflow_artifacts_root}/knowledge-bank/anti-patterns.md`
3. For each heuristic in `act.heuristics`:
   - Append to `{iflow_artifacts_root}/knowledge-bank/heuristics.md`

Each entry format:
```markdown
### {Type}: {Name}
{Text}
- Observed in: {provenance}      ← use "Source:" instead for heuristics.md
- Confidence: {confidence}
- Last observed: Feature #{NNN}
- Observation count: 1
```

If a knowledge-bank file doesn't exist, create it with a header:
```markdown
# {Patterns|Anti-Patterns|Heuristics}

Accumulated learnings from feature retrospectives.
```

### Step 4b: Validate Knowledge Bank (Pre-Existing Entries)

Performed by the orchestrating agent inline (not a sub-agent dispatch). Only validates `anti-patterns.md` and `heuristics.md` (not `patterns.md`).

**a. Read all entries** from `{iflow_artifacts_root}/knowledge-bank/anti-patterns.md` and `{iflow_artifacts_root}/knowledge-bank/heuristics.md` (~15 entries total).

**b. Identify pre-existing entries** — exclude entries just added in Step 4 by comparing entry names against the retro-facilitator's `act.anti_patterns` and `act.heuristics` output. Only pre-existing entries proceed to validation.

**c. Determine relevance** for each pre-existing entry:
- **RELEVANT** if the entry's domain (file patterns, coding practices, workflow steps) overlaps with this feature's git diff files, implementation-log decisions/deviations, or review-history issues (all already in context from Step 1)
- **NOT RELEVANT** if the entry's domain has no overlap — skip, no update needed

**d. Evaluate relevant entries** against this feature's experience:

| Verdict | Condition | Action |
|---------|-----------|--------|
| CONFIRMED | Feature experience aligns with entry's guidance | Update `Last observed: Feature #{id}`, increment `Observation count` |
| CONTRADICTED | Feature experience contradicts the entry | Append `- Challenged: Feature #{id} — {specific contradiction}` to the entry |

**e. Staleness check** (mechanical, not LLM-judgment):

1. For each pre-existing entry, extract the feature number NNN from `Last observed: Feature #{NNN}`
2. Glob `{iflow_artifacts_root}/features/` directories, extract numeric prefix (pattern: `/^(\d+)-/`), count directories with numeric ID > NNN
3. If count >= 10: flag entry as STALE
4. Surface all stale entries to user via AskUserQuestion:
   ```
   AskUserQuestion:
     questions: [{
       "question": "The following entries haven't been observed in 10+ features:\n{list with entry names and last-observed feature numbers}\n\nFor each entry, choose an action.",
       "header": "Stale Knowledge Bank Entries",
       "options": [
         {"label": "Keep", "description": "Remove stale marker, update Last observed to current feature"},
         {"label": "Update", "description": "Provide new text, modify in-place, reset Observation count to 1"},
         {"label": "Retire", "description": "Delete entry from file, note in retro.md"}
       ],
       "multiSelect": false
     }]
   ```
5. Apply user's choice per entry:
   - **Keep**: Remove stale marker, update `Last observed` to current feature, `Observation count` unchanged
   - **Update**: User provides new text, modify entry in-place, update `Last observed`, reset `Observation count` to 1
   - **Retire**: Delete entry from file, append to `retro.md`: `Retired: {entry name} — {user's reason}`

### Step 4c: Promote to Global Store

For each NEW entry written in Step 4 (not pre-existing entries from 4b):

1. Classify as `universal` or `project-specific` with reasoning:
   - Universal: "Always read target file before editing" (no project refs), "Break tasks into one-file-per-task" (general workflow)
   - Project-specific: "Secretary routing table must match hooks.json" (iflow architecture), "session-start.sh Python subprocess adds ~200ms" (specific file)
   - Default to `universal` — over-sharing is better than under-sharing

2. For universal entries:
   - Compute content hash: `echo "DESCRIPTION" | python3 -c "import sys,hashlib; print(hashlib.sha256(' '.join(sys.stdin.read().lower().strip().split()).encode()).hexdigest()[:16])"`
   - Read global store file at `~/.claude/iflow/memory/{category}.md` (create dir with `mkdir -p` if needed)
   - If hash match: increment `Observation count`, update `Last observed`, append project to `Source`
   - If no match: append entry with full schema (Content-Hash, Source, Observation count: 1, Last observed, Tags: universal, Confidence)

3. For project-specific entries: skip, log reason

4. Output: "Memory promotion: N universal promoted, M project-specific kept local"

### Step 5: Commit

```bash
git add {iflow_artifacts_root}/features/{id}-{slug}/retro.md {iflow_artifacts_root}/knowledge-bank/
git commit -m "docs: AORTA retrospective for feature {id}-{slug}"
git push
```

## Graceful Degradation

| Condition | Behavior |
|-----------|----------|
| `.review-history.md` missing | Agent runs with metrics-only (Observe works, Review limited) |
| `.meta.json` has no phase data | Agent notes "insufficient data", produces minimal retro |
| retro-facilitator agent fails | Fall back to investigation-agent (Step 2 fallback) |
| No git data available | Omit git summary from context bundle |
| `retro.md` exists but KB not updated | Recovery via Step 0 — parse Act section, persist missing entries |

## Output

```
Retrospective complete (AORTA framework).
Updated: {list of knowledge-bank files updated}
Saved to retro.md.
```

## Automatic Execution

This skill runs automatically during `/iflow:finish-feature`:
- No permission prompt required
- Findings drive knowledge bank updates
- User sees summary of learnings captured

## Config Variables
Use these values from session context (injected at session start):
- `{iflow_artifacts_root}` — root directory for feature artifacts (default: `docs`)
- `{iflow_base_branch}` — base branch for merges (default: `main`)

## Read Feature Context

1. Find active feature folder in `{iflow_artifacts_root}/features/`
2. Read `.meta.json` for mode and context
